{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hadoop配置\n",
    "\n",
    "- [hadoop基础知识](hadoop基础知识.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- java JDK(下载jdk解压配置环境变量)\n",
    "- nc(网络安全工具)\n",
    "- gcc\n",
    "- bashdb（下载bashdb, 配置、编译、安装）\n",
    "- apache\n",
    "- nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 节点规划\n",
    "\n",
    "|主机名称| IP地址 | 功能|\n",
    "|:---:|:----|:-----|\n",
    "|hadoop1|192.168.75.111|NameNode、DataNode、resourcemanager、nodemanager|\n",
    "|hadoop2|192.168.75.111|DataNode、nodemanager|\n",
    "|hadoop3|192.168.75.111|DataNode、nodemanager|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建虚拟机配置网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 手动配置DHCP\n",
    "- 修改域名，在/etc/sysconfig/network中添加HOSTNAME=hadoop1\n",
    "- 把域名添加到/etc/hosts中\n",
    "```\n",
    "192.168.75.111 hadoop1 www.hadoop1.com\n",
    "```\n",
    "\n",
    "- 修改/etc/sysconfig/network-scripts/ifcfg-ens33文件\n",
    "    - 添加DNS和网关一样\n",
    "    - ONBOOT=yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 安装nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [pcre](http://www.pcre.org/)\n",
    "\n",
    "```\n",
    "tar zxvf pcre-8.36.tar.gz\n",
    "cd pcre-8.36\n",
    "./configure && make && make install\n",
    "```\n",
    "\n",
    "- [openssl](http://www.openssl.org/ ) \n",
    "```\n",
    " tar zxvf openssl-1.1.1.tar.gz\n",
    "cd openssl-fips-1.1.1\n",
    "./config && make && make install\n",
    "```\n",
    "- [zlib](http://www.zlib.net/)\n",
    "```\n",
    "tar zxvf zlib-1.2.11.tar.gz\n",
    "cd zlib-1.2.11\n",
    "./configure && make && make install\n",
    "```\n",
    "- [nginx](http://nginx.org/download/)\n",
    "\n",
    "```\n",
    "tar zxvf nginx-1.14.0.tar.gz\n",
    "cd nginx-1.14.0\n",
    " ./configure && make && make install\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单机版hadoop配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下载[hadoop](http://hadoop.apache.org/releases.html)\n",
    "- 解压压缩包到`/usr/local/`目录\n",
    "- 配置环境变量\n",
    "- 修改hadoop/etc/hadoop/hadoop-env.sh文件中的JAVA环境变量为JDK路径\n",
    "- 测试\n",
    "```\n",
    "    which hadoop\n",
    "    hadoop version\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "$ mkdir /home/htfeng/data/input\n",
    "$ cp hadoop/etc/hadoop/*.xml /home/htfeng/data/input\n",
    "$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar grep /home/htfeng/data/input /home/htfeng/data/output 'dfs[a-z.]+'\n",
    "$ cat /home/htfeng/data/output/*\n",
    "$ hdfs dfs -ls /\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 克隆虚拟机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 修改网卡信息（忽略）\n",
    "\n",
    "```\n",
    "vi /etc/udev/rules.d/70-persistent-ipoib.rules \n",
    "```\n",
    "\n",
    "- 修改主机名\n",
    "\n",
    "```\n",
    "vi /etc/sysconfig/network\n",
    "```\n",
    "\n",
    "- 修改ip信息\n",
    "\n",
    "```\n",
    "vi /etc/sysconfig/network-scripts/ifcfg-ens33\n",
    "\n",
    "修改ip、硬件地址和UUID\n",
    "```\n",
    "\n",
    "- 修改映射\n",
    "\n",
    "```\n",
    "vi /etc/hosts  \n",
    "\n",
    "192.168.75.112 hadoop2 www.hadoop2.com\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集群配置\n",
    "\n",
    "- 配置JDK\n",
    "- 配置hadoop\n",
    "- 配置hadoop-env.sh\n",
    "- 配置hadoop-core-site.xml\n",
    "- 配置hadoop-hdfs-site.xml\n",
    "- 配置hadoop-mapred-site.xml\n",
    "- 配置hadoop-yarn-site.xml\n",
    "- 配置slave\n",
    "- 发送hadoop文件到所有机子上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**配置core-site.xml**\n",
    "```xml\n",
    "<configuration>\n",
    "<!--hdfs filesystem namespace-->\n",
    "    <property>\n",
    "        <name>fs.defaultFS</name>\n",
    "        <value>hadoop1:9000</value>\n",
    "    </property>\n",
    "<!--hdfs cache-->\n",
    "    <property>\n",
    "        <name>io.file.buffer.size</name>\n",
    "        <value>4096</value>\n",
    "    </property>\n",
    "<!--tmp data-->\n",
    "    <property>\n",
    "        <name>hadoop.tmp.dir</name>\n",
    "        <value>/home/htfeng/tmp/</value>\n",
    "    </property>\n",
    "    \n",
    "    <property>\n",
    "        <name>fs.hdfs.impl</name>\n",
    "        <value>org.apache.hadoop.hdfs.DistributedFileSystem</value>\n",
    "        <description>The FileSystem for hdfs: uris.</description>\n",
    "    </property>\n",
    "</configuration>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**配置hadoop-hdfs-site.xml**\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>dfs.replication</name>\n",
    "        <value>3</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.block.size</name>\n",
    "        <value>134217728</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.namenode.name.dir</name>\n",
    "        <value>/home/htfeng/hadoopdata/dfs/name</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.datanode.data.dir</name>\n",
    "        <value>/home/htfeng/hadoopdata/dfs/data</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.checkpoint.dir</name>\n",
    "        <value>/home/htfeng/hadoopdata/checkpoint/dfs/name</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.http.address</name>\n",
    "        <value>hadoop1:50070</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.secondary.http.address</name>\n",
    "        <value>hadoop1:50090</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.webhdfs.enabled</name>\n",
    "        <value>false</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.permissions</name>\n",
    "        <value>false</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**配置hadoop-mapred-site.xml**\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>mapreduce.framework.name</name>\n",
    "        <value>yarn</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>mapreduce.jobhistory.address</name>\n",
    "        <value>hadoop1:10020</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>mapreduce.jobhistory.webapp.address</name>\n",
    "        <value>hadoop1:19888</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**配置hadoop-yarn-site.xml**\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "\n",
    "    <property>\n",
    "        <name>yarn.nodemanager.aux-services</name>\n",
    "        <value>mapreduce_shuffle</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>yarn.resourcemanager.hostname</name>\n",
    "        <value>hadoop1</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>yarn.resourcemanager.address</name>\n",
    "        <value>hadoop1:8032</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>yarn.resourcemanager.scheduler.address</name>\n",
    "        <value>hadoop1:8030</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>yarn.resourcemanager.resource-tracker.address</name>\n",
    "        <value>hadoop1:8031</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>yarn.resourcemanager.admin.address</name>\n",
    "        <value>hadoop1:8033</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>yarn.resourcemanager.webapp.address</name>\n",
    "        <value>hadoop1:8088</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**配置slave**\n",
    "\n",
    "```\n",
    "hadoop1\n",
    "hadoop2\n",
    "hadoop3\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 发送hadoop文件到所有机子上 **\n",
    "\n",
    "```\n",
    "scp -r ../hadoop-2.8.4/ hadoop2:/usr/local/\n",
    "scp -r ../hadoop-2.8.4/ hadoop3:/usr/local/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**启动之前在namenode服务器上格式化，只需一次即可**\n",
    "\n",
    "- 关闭防火墙\n",
    "\n",
    "```\n",
    "systemctl stop firewalld.service\n",
    "```\n",
    "\n",
    "```\n",
    "hadoop namenode -format\n",
    "\n",
    "全启动：start-all.sh\n",
    "模块启动：\n",
    "start-dfs.sh\n",
    "start-yarn.sh\n",
    "单个进程启动\n",
    "hadoop-daemon.sh start/stop namenode\n",
    "hadoop-daemons.sh start/stop datanode\n",
    "yarn-daemon.sh start/stop namenode\n",
    "yarn-daemons.sh start/stop datanode\n",
    "mr-jobhistory-daemon.sh start/stop historyserver\n",
    "```\n",
    "\n",
    "> netstat -tnpl:查看启动端口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 启动start-dfs.sh测试\n",
    "```\n",
    "http://192.168.75.111:50070\n",
    "```\n",
    "- 上传和下载文件（测试hdfs）\n",
    "```\n",
    "hdfs dfs -put ./README.txt /\n",
    "```\n",
    "- 启动start-yarn.sh跑一个mapreduce作业\n",
    "```\n",
    "yarn jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.4.jar wordcount /README.txt /out/00\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 免密登录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "ssh-keygen -t rsa\n",
    "ssh-copy-id hadoop1\n",
    "ssh-copy-id hadoop2\n",
    "ssh-copy-id hadoop3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDFS shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hdfs的shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "命令和shell命令基本一致\n",
    "\n",
    "```shell\n",
    "hdfs dfs -\n",
    "\n",
    "Usage: hadoop fs [generic options]\n",
    "\t[-appendToFile <localsrc> ... <dst>]\n",
    "\t[-cat [-ignoreCrc] <src> ...]\n",
    "\t[-checksum <src> ...]\n",
    "\t[-chgrp [-R] GROUP PATH...]\n",
    "\t[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]\n",
    "\t[-chown [-R] [OWNER][:[GROUP]] PATH...]\n",
    "\t[-copyFromLocal [-f] [-p] [-l] [-d] <localsrc> ... <dst>]\n",
    "\t[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n",
    "\t[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] <path> ...]\n",
    "\t[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]\n",
    "\t[-createSnapshot <snapshotDir> [<snapshotName>]]\n",
    "\t[-deleteSnapshot <snapshotDir> <snapshotName>]\n",
    "\t[-df [-h] [<path> ...]]\n",
    "\t[-du [-s] [-h] [-x] <path> ...]\n",
    "\t[-expunge]\n",
    "\t[-find <path> ... <expression> ...]\n",
    "\t[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n",
    "\t[-getfacl [-R] <path>]\n",
    "\t[-getfattr [-R] {-n name | -d} [-e en] <path>]\n",
    "\t[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]\n",
    "\t[-help [cmd ...]]\n",
    "\t[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [<path> ...]]\n",
    "\t[-mkdir [-p] <path> ...]\n",
    "\t[-moveFromLocal <localsrc> ... <dst>]\n",
    "\t[-moveToLocal <src> <localdst>]\n",
    "\t[-mv <src> ... <dst>]\n",
    "\t[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]\n",
    "\t[-renameSnapshot <snapshotDir> <oldName> <newName>]\n",
    "\t[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]\n",
    "\t[-rmdir [--ignore-fail-on-non-empty] <dir> ...]\n",
    "\t[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]\n",
    "\t[-setfattr {-n name [-v value] | -x name} <path>]\n",
    "\t[-setrep [-R] [-w] <rep> <path> ...]\n",
    "\t[-stat [format] <path> ...]\n",
    "\t[-tail [-f] <file>]\n",
    "\t[-test -[defsz] <path>]\n",
    "\t[-text [-ignoreCrc] <src> ...]\n",
    "\t[-touchz <path> ...]\n",
    "\t[-truncate [-w] <length> <path> ...]\n",
    "\t[-usage [cmd ...]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "hdfs dfs -ls /   \n",
    "hadoop fs - /  \n",
    "hdfs dfs -ls -R / #递归查看  \n",
    "hdfs dfs -mkdir -p /  #递归创建\n",
    "hdfs dfs -touchz  /test/te.txt\n",
    "hdfs dfs -put ./if.sh /if.sh  # 本地目录上传到hdfs文件目录\n",
    "hdfs dfs -get /if.sh /home/htfeng  #从hdfs文件目录下载\n",
    "hdfs dfs -du -s / #统计目录大小\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### window中安装maven\n",
    "\n",
    "- 下载[maven](http://mirrors.shu.edu.cn/apache/maven/maven-3/3.5.3/binaries/apache-maven-3.5.3-bin.zip)\n",
    "- 解压并复制到一个目录\n",
    "- 配置环境变量\n",
    "- 配置maven，修改settings.xml文件，指定本地仓库位置`H:\\hadoop\\mvnrepositry`， [maven](http://mvnrepository.com/)库\n",
    "- 和java的编辑工具整合（eclipse,idea,myeclipse等）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[maven项目测试](maven测试.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hadoop核心协议RPC（远程过程调用协议）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例子\n",
    "\n",
    "- 建一个rpc的包，然后创建下面三个java脚本,[具体代码](RPC.ipynb)\n",
    "    - hello.java\n",
    "    - RPCServer.java\n",
    "    - RPCClient.java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
