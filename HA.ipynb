{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [HDFS的HA基础](http://hadoop.apache.org/docs/r2.8.4/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果namenode出现问题，整个HDFS集群将不能使用。     \n",
    "- 是不是可以有两个namenode呢  \n",
    "    - 一个为对外服务->active  \n",
    "    - 一个处于待机->standby    \n",
    "    - 他们的之间共享的元数据叫 nameservice  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDFS HA的几大中重点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 保证两个namenode里面的内存中存储的文件的元数据同步   \n",
    "    - namenode启动时，会读镜像文件   \n",
    "- 变化的记录信息同步  \n",
    "- 日志文件的安全性   \n",
    "    - 分布式的存储日志文件（cloudera公司提出来的）  \n",
    "        - 2n+1个，使用副本数保证安全性  \n",
    "    - 使用zookeeper监控  \n",
    "        - 监控两个namenode，当一个出现了问题，可以达到自动故障转移。  \n",
    "        - 如果出现了问题，不会影响整个集群   \n",
    "        - zookeeper对时间同步要求比较高。   \n",
    "- 客户端如何知道访问哪一个namenode  \n",
    "    - 使用proxy代理     \n",
    "    - 隔离机制   \n",
    "    - 使用的是sshfence  \n",
    "    - 两个namenode之间无密码登录   \n",
    "- namenode是哪一个是active   \n",
    "    - zookeeper通过选举选出zookeeper。  \n",
    "    - 然后zookeeper开始监控，如果出现文件，自动故障转移。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置hadoop-env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "export JAVA_HOME=/usr/local/jdk1.8.0_171/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置hadoop-core-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```xml\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>fs.defaultFS</name>\n",
    "        <value>hdfs://htfeng</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>io.file.buffer.size</name>\n",
    "        <value>4096</value>\n",
    "    </property>\n",
    "<!--tmp data-->\n",
    "    <property>\n",
    "        <name>hadoop.tmp.dir</name>\n",
    "        <value>/home/htfeng/hahadoopdata/tmp/</value>\n",
    "    </property>\n",
    "\n",
    "</configuration>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置hadoop-hdfs-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```xml\n",
    "<configuration>\n",
    "    <property>\n",
    "        <name>dfs.replication</name>\n",
    "        <value>3</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.block.size</name>\n",
    "        <value>134217728</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.namenode.name.dir</name>\n",
    "        <value>/home/htfeng/hahadoopdata/dfs/name</value>\n",
    "    </property>\n",
    "    <property>\n",
    "        <name>dfs.datanode.data.dir</name>\n",
    "        <value>/home/htfeng/hahadoopdata/dfs/data</value>\n",
    "    </property>\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.nameservices</name>\n",
    "      <value>htfeng</value>\n",
    "    </property>\n",
    "    <property>\n",
    "      <name>dfs.ha.namenodes.htfeng</name>\n",
    "      <value>nn1,nn2</value>\n",
    "    </property>\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.namenode.rpc-address.htfeng.nn1</name>\n",
    "      <value>hadoop1:9000</value>\n",
    "    </property>\n",
    "    <property>\n",
    "      <name>dfs.namenode.rpc-address.htfeng.nn2</name>\n",
    "      <value>hadoop2:9000</value>\n",
    "    </property>\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.namenode.http-address.htfeng.nn1</name>\n",
    "      <value>hadoop1:50070</value>\n",
    "    </property>\n",
    "    <property>\n",
    "      <name>dfs.namenode.http-address.htfeng.nn2</name>\n",
    "      <value>hadoop2:50070</value>\n",
    "    </property>\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.namenode.shared.edits.dir</name>\n",
    "      <value>qjournal://hadoop1:8485;hadoop2:8485;hadoop3:8485/htfeng</value>\n",
    "    </property>\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.journalnode.edits.dir</name>\n",
    "      <value>/home/htfeng/hahadoopdata/journal/data</value>\n",
    "    </property>\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.ha.automatic-failover.enabled</name>\n",
    "      <value>true</value>\n",
    "    </property>\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.client.failover.proxy.provider.htfeng</name>\n",
    "                                       <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n",
    "    </property>\n",
    "\n",
    "   <property>\n",
    "      <name>dfs.ha.fencing.methods</name>\n",
    "      <value>sshfence</value>\n",
    "    </property>\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.ha.fencing.ssh.private-key-files</name>\n",
    "      <value>/root/.ssh/id_rsa</value>\n",
    "    </property>\n",
    "\n",
    "\n",
    "    <property>\n",
    "      <name>dfs.ha.fencing.ssh.connect-timeout</name>\n",
    "      <value>30000</value>\n",
    "    </property>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置slaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "hadoop1\n",
    "hadoop2\n",
    "hadoop3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 配置yarn-site.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```xml\n",
    "<configuration>\n",
    "\n",
    "<!-- Site specific YARN configuration properties -->\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.ha.enabled</name>\n",
    "  <value>true</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.cluster-id</name>\n",
    "  <value>htfengyarn</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.ha.rm-ids</name>\n",
    "  <value>rm1,rm2</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.hostname.rm1</name>\n",
    "  <value>hadoop1</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.hostname.rm2</name>\n",
    "  <value>hadoop2</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.webapp.address.rm1</name>\n",
    "  <value>hadoop1:8088</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.webapp.address.rm2</name>\n",
    "  <value>hadoop2:8088</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.zk-address</name>\n",
    "  <value>hadoop1:2181,hadoop2:2181,hadoop3:2181</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>yarn.nodemanager.aux-services</name>\n",
    "  <value>mapreduce_shuffle</value>\n",
    "</property>\n",
    "</configuration>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**配置mapred-site.xml**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```xml\n",
    "<configuration>\n",
    "     <property>\n",
    "        <name>mapreduce.framework.name</name>\n",
    "        <value>yarn</value>\n",
    "    </property>\n",
    "</configuration>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
