{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**新建maven项目**\n",
    "\n",
    "- 安装jdk-1.8\n",
    "- 修改eclipse->window->Preferences->maven->Installion(添加maven地址) and user settings(改为本地库)\n",
    "- 打开eclipse，新建maven项目\n",
    "- 修改pom.xml文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```xml\n",
    "  <properties>\n",
    "    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n",
    "    <hadoop.version>2.8.4</hadoop.version>\n",
    "  </properties>\n",
    "\n",
    "  <dependencies>\n",
    "    <dependency>\n",
    "      <groupId>junit</groupId>\n",
    "      <artifactId>junit</artifactId>\n",
    "      <version>3.8.1</version>\n",
    "      <scope>test</scope>\n",
    "    </dependency>\n",
    "    \n",
    "    <dependency>\n",
    "      <groupId>jdk.tools</groupId>\n",
    "      <artifactId>jdk.tools</artifactId>\n",
    "      <version>1.9</version>\n",
    "      <scope>system</scope>\n",
    "      <systemPath>${JAVA_HOME}/lib/tools.jar</systemPath>\n",
    "    </dependency>\n",
    "    \n",
    "    <!-- hadoop start -->\n",
    "    <dependency>\n",
    "      <groupId>org.apache.hadoop</groupId>\n",
    "      <artifactId>hadoop-common</artifactId>\n",
    "      <version>${hadoop.version}</version>\n",
    "    </dependency>\n",
    "    \n",
    "    <dependency>\n",
    "      <groupId>org.apache.hadoop</groupId>\n",
    "      <artifactId>hadoop-client</artifactId>\n",
    "      <version>${hadoop.version}</version>\n",
    "    </dependency>\n",
    "    \n",
    "    <dependency>\n",
    "      <groupId>org.apache.hadoop</groupId>\n",
    "      <artifactId>hadoop-hdfs</artifactId>\n",
    "      <version>${hadoop.version}</version>\n",
    "    </dependency>\n",
    "  </dependencies>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**java读取hdfs的文件**\n",
    "\n",
    "- 在新建的项目/src/main/java/创建一个包\n",
    "- 修改包的.java文件(我新建的包是test.Hdfs，新建的文件是test.java)\n",
    "\n",
    "**java操作hdfs文件系统**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```java\n",
    "package test.Hdfs;\n",
    "\n",
    "import java.io.File;\n",
    "import java.io.FileOutputStream;\n",
    "import java.io.IOException;\n",
    "import java.io.OutputStream;\n",
    "import java.net.URI;\n",
    "\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.FSDataInputStream;\n",
    "import org.apache.hadoop.fs.FileSystem;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IOUtils;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/**\n",
    " * 用java代码操作hdfs文件系统\n",
    " * @author htfeng\n",
    " *\n",
    " */\n",
    "public class HdfsTest {\n",
    "\t\n",
    "\tstatic FileSystem fs = null;\n",
    "\tstatic {\n",
    "\t\t//获取配置文件\n",
    "\t\tConfiguration  conf = new Configuration();\n",
    "\t\t//获取hdfs文件操作系统操作对象\n",
    "\t\ttry {\n",
    "\t\t\tfs = FileSystem.get(new URI(\"hdfs://192.168.75.111:9000\"), conf, \"root\");\n",
    "\t\t} catch (Exception e) {\n",
    "\t\t\te.printStackTrace();\n",
    "\t\t} \n",
    "\t}\n",
    "\t\n",
    "\tpublic static void main(String[] args) throws IOException {\n",
    "\t\t//readFileToConsole(\"/out/00/part-r-00000\");\n",
    "\t\t//readFileToLocal(\"/out/00/part-r-00000\");\n",
    "\t\tcopyFromLocal();\n",
    "\t}\n",
    "\t\n",
    "\t//读取hdfs文件系统的文件\n",
    "\tpublic\tstatic void readFileToConsole(String path) throws IOException {\n",
    "\t\t//获取配置文件\n",
    "\t\tConfiguration  conf = new Configuration();\n",
    "\t\t//conf.set(\"fs.hdfs.impl\",org.apache.hadoop.hdfs.DistributedFileSystem.class.getName()); \n",
    "\t\tconf.set(\"fs.defaultFS\", \"hdfs://192.168.75.111:9000\");\n",
    "\t\t//获取hdfs文件操作系统操作对象\n",
    "\t\tFileSystem fs = FileSystem.get(conf);\n",
    "\t\t//具体对文件的操作\n",
    "\t\tFSDataInputStream fis = fs.open(new Path(path));\n",
    "\t\tIOUtils.copyBytes(fis, System.out, 4096, true);\n",
    "\t}\n",
    "\t\n",
    "\tpublic\tstatic void readFileToLocal(String path) throws IOException {\n",
    "\t\tFSDataInputStream fis = null;\n",
    "\t\tOutputStream out = null;\n",
    "\t\ttry {\n",
    "\t\t\t//获取配置文件\n",
    "\t\t\tConfiguration  conf = new Configuration();\n",
    "\t\t\t//获取hdfs文件操作系统操作对象\n",
    "\t\t\tFileSystem fs = FileSystem.get(new URI(\"hdfs://192.168.75.111:9000\"), conf, \"root\");\n",
    "\t\t\t//具体对文件的操作\n",
    "\t\t\tfis = fs.open(new Path(path));\n",
    "\t\t    out = new FileOutputStream(new File(\"H:\\\\hadoop\\\\hadoopdata\\\\test01.txt\"));\n",
    "\t\t\tIOUtils.copyBytes(fis, out, 4096, true);\n",
    "\t\t} catch (Exception e) {\n",
    "\t\t\t// \n",
    "\t\t} finally {\n",
    "\t\t\tfis.close();\n",
    "\t\t\tout.close();\n",
    "\t\t}\n",
    "\t}\n",
    "\t\n",
    "\t//将window中的文件上传到hdfs文件系统\n",
    "\tpublic\tstatic void copyFromLocal() throws IOException {\n",
    "\t\tfs.copyFromLocalFile(new Path(\"H:\\\\hadoop\\\\hadoopdata\\\\test01.txt\"), new Path(\"/test/123\"));\n",
    "\t\tSystem.out.println(\"finished...\");\n",
    "\t}\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
